import asyncio
from collections import defaultdict
import logging
import json
import hashlib

import numpy as np

from kriging import Interpolator
from mcp_server import mcp_server
from pprint import pformat
from prompt import SYSTEM_TO_STRATA
from ahp_calculator import calculate_ahp_weights
# ------------------------
# æŠ½è±¡ Agent
# ------------------------
class Agent:
    async def run(self, ctx, context: dict) -> dict:
        """å¿…é¡»å®ç° run æ–¹æ³•"""
        raise NotImplementedError("Agent å¿…é¡»å®ç° run æ–¹æ³•")

# ------------------------
# DummyContextï¼Œç”¨äºæµ‹è¯•æˆ–æ—  MCP æ¨¡å¼
# ------------------------
class DummyContext:
    async def info(self, msg: str, **kwargs):
        logging.info(msg)

    async def report_progress(self, progress, total=1.0, message=""):
        logging.info(f"[PROGRESS] {progress*100:.1f}% - {message}")

    async def error(self, msg: str, **kwargs):
        logging.error(msg)

class ExtendedContext:
    def __init__(self, ctx=None):
        self.ctx = ctx

    @classmethod
    def from_context(cls, ctx):
        return cls(ctx)

    async def info(self, msg: str):
        if hasattr(self.ctx, "info"):
            try:
                await self.ctx.info(msg)
                return
            except Exception:
                pass
        logging.info(msg)

    async def error(self, msg: str):
        if hasattr(self.ctx, "error"):
            try:
                await self.ctx.error(msg)
                return
            except Exception:
                pass
        logging.error(msg)

    async def report_progress(self, progress: float, total: float = 1.0, message: str = ""):
        if hasattr(self.ctx, "report_progress"):
            try:
                await self.ctx.report_progress(progress, total, message)
                return
            except Exception:
                pass
        logging.info(f"[PROGRESS] {progress*100:.1f}% {message}")

    async def call_tool(self, name: str, **kwargs):
        """
        ä¼˜å…ˆä½¿ç”¨ ctx.call_toolï¼Œå¦åˆ™ fallback åˆ°å…¨å±€ mcp_serverã€‚
        å†…ç½®ç²¾ç»†åŒ–ç¼“å­˜é€»è¾‘ã€‚
        """
        # --- 1. ç”Ÿæˆç¼“å­˜é”® ---
        # ç§»é™¤ ctx å‚æ•°ï¼Œå› ä¸ºå®ƒä¼šå˜åŒ–ä¸”ä¸å½±å“ç»“æœ
        kwargs_for_key = {k: v for k, v in kwargs.items() if k != 'ctx'}

        # å®šä¹‰ä¸€ä¸ªè½¬æ¢å‡½æ•°æ¥å¤„ç† Decimal å’Œå…¶ä»–éåºåˆ—åŒ–ç±»å‹
        def json_converter(o):
            if isinstance(o, np.ndarray):
                return o.tolist()
            if hasattr(o, 'isoformat'): # å¤„ç† datetime å¯¹è±¡
                return o.isoformat()
            # å…³é”®ï¼šå¤„ç† Decimal ç±»å‹
            from decimal import Decimal
            if isinstance(o, Decimal):
                return float(o)
            raise TypeError(f"Object of type {o.__class__.__name__} is not JSON serializable")

        # å°†å‚æ•°å­—å…¸è½¬æ¢ä¸ºç¨³å®šçš„ã€æ’åºåçš„ JSON å­—ç¬¦ä¸²
        try:
            params_str = json.dumps(kwargs_for_key, sort_keys=True, ensure_ascii=False, default=json_converter)
        except TypeError as e:
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯æ—¥å¿—ï¼Œå¸®åŠ©å®šä½é—®é¢˜
            logging.error(f"æ— æ³•åºåˆ—åŒ–å·¥å…· '{name}' çš„å‚æ•°ç”¨äºç”Ÿæˆç¼“å­˜é”®: {e}")
            # ä¸ºäº†é¿å…ç¨‹åºä¸­æ–­ï¼Œå¯ä»¥é€‰æ‹©ä¸ä½¿ç”¨ç¼“å­˜ç»§ç»­æ‰§è¡Œ
            # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©é‡æ–°æŠ›å‡ºï¼Œå› ä¸ºç¼“å­˜æ˜¯æ ¸å¿ƒåŠŸèƒ½
            raise e
            
        # ä½¿ç”¨ MD5 ç”Ÿæˆç®€çŸ­çš„å“ˆå¸Œå€¼ä½œä¸ºé”®
        cache_key_hash = hashlib.md5(params_str.encode('utf-8')).hexdigest()
        cache_key = f"{name}::{cache_key_hash}"

        # --- 2. æ£€æŸ¥ç¼“å­˜ ---
        if cache_key in mcp_server.context.run_cache:
            await self.info(f"âœ… å·¥å…· '{name}' ç¼“å­˜å‘½ä¸­ (Key: ...{cache_key_hash[-6:]})")
            return mcp_server.context.run_cache[cache_key]

        await self.info(f"ğŸš€ æ‰§è¡Œå·¥å…· '{name}' (æ— ç¼“å­˜, Key: ...{cache_key_hash[-6:]})")

        # --- 3. æ‰§è¡Œå·¥å…· ---
        # ç¡®ä¿ ctx å‚æ•°å§‹ç»ˆä¼ å…¥
        if "ctx" not in kwargs:
            kwargs["ctx"] = self  # self æ˜¯ ExtendedContext

        result = None
        try:
            # å…ˆå°è¯• MCP Context å†…è°ƒç”¨
            if hasattr(self, "_ctx") and hasattr(self._ctx, "call_tool"):
                try:
                    result = await self._ctx.call_tool(name, **kwargs)
                except Exception:
                    logging.warning(f"âš ï¸ MCP Context è°ƒç”¨ {name} å¤±è´¥ï¼Œå°è¯•å…¨å±€ mcp_server")
                    result = None # ç¡®ä¿åœ¨å¤±è´¥æ—¶ result ä¸º None

            # å¦‚æœä¸Šä¸€æ­¥æ²¡æˆåŠŸï¼Œåˆ™ fallback å…¨å±€ mcp_server
            if result is None:
                tool = mcp_server._local_tools.get(name)
                if not tool:
                    raise RuntimeError(f"å·¥å…· {name} æœªæ³¨å†Œ")

                if asyncio.iscoroutinefunction(tool):
                    result = await tool(**kwargs)
                else:
                    result = tool(**kwargs)

        except Exception as e:
            await self.error(f"âŒ å·¥å…· '{name}' æ‰§è¡Œå¤±è´¥: {e}")
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚é€»è¾‘å¤„ç†

        # --- 4. å†™å…¥ç¼“å­˜ ---
        if result is not None:
            mcp_server.context.run_cache[cache_key] = result
            await self.info(f"ğŸ“ å·¥å…· '{name}' ç»“æœå·²å†™å…¥ç¼“å­˜")

        return result


# ------------------------
# NLP Agent
# ------------------------
class NLPAgent(Agent):
    async def run(self, ctx: ExtendedContext, context: dict) -> dict:
        text = context.get("text")
        if not text:
            context.setdefault("errors", []).append("ç¼ºå°‘ text")
            context["plan"] = {"pipeline": []}
            return context

        try:
            # 1. è°ƒç”¨ NLP å·¥å…·è§£æ
            nlp_result = await ctx.call_tool(
                "parse_text_tool_mcp",
                user_text=text,
                context=context
            )
            task = nlp_result.get("task", {})
            plan = nlp_result.get("plan", {"pipeline": []})

            # 2. åŠ¨æ€è°ƒæ•´ plan ä»¥åŠ å…¥ OverlayAgent
            analysis_type = task.get("analysis_type")
            if analysis_type == "multi_factor":
                pipeline = plan.get("pipeline", [])
                try:
                    kriging_index = pipeline.index("kriging")
                    # åœ¨ kriging ä¹‹åï¼Œimage ä¹‹å‰æ’å…¥ overlay
                    if "overlay" not in pipeline:
                        pipeline.insert(kriging_index + 1, "overlay")
                    plan["pipeline"] = pipeline
                    await ctx.info("âœ… æ£€æµ‹åˆ°å¤šå› ç´ åˆ†æä»»åŠ¡ï¼Œå·²åœ¨æµç¨‹ä¸­åŠ å…¥ OverlayAgent")
                except ValueError:
                    await ctx.warning("âš ï¸ å¤šå› ç´ ä»»åŠ¡çš„ plan ä¸­æœªæ‰¾åˆ° 'kriging'ï¼Œæ— æ³•è‡ªåŠ¨æ’å…¥ 'overlay'")
            
            context["task"] = task
            context["plan"] = plan

            # 3. å‚æ•°ç»§æ‰¿ä¸åˆå¹¶
            last_params = getattr(mcp_server, "context", {}).params or {}
            context["params"] = {**last_params, **task}

            # 4. å†™å› MCPContext
            mcp_server.context.task.update(task)
            mcp_server.context.params.update(context["params"])
            mcp_server.context.task["plan"] = plan

            # 5. è¾“å‡ºçŠ¶æ€
            await ctx.info(" NLPAgent æ‰§è¡Œåï¼Œå…¨å±€ MCPContext çŠ¶æ€ï¼š")
            await ctx.info(pformat({
                "task": mcp_server.context.task,
                "params": mcp_server.context.params,
                "plan": plan
            }, width=80))

        except Exception as e:
            context.setdefault("errors", []).append(str(e))
            await ctx.error(f"NLP è§£æå¤±è´¥: {e}")

        return context


# ------------------------
# Feedback Agent
# ------------------------
class FeedbackAgent(Agent):
    async def run(self, ctx: ExtendedContext, context: dict) -> dict:
        feedback_text = context.get("feedback")
        if not feedback_text:
            await ctx.info("âš ï¸ æ— ç”¨æˆ·åé¦ˆï¼Œè·³è¿‡ FeedbackAgent")
            return context

        # --- ç¼“å­˜å¤±æ•ˆé€»è¾‘ ---
        # å½“æœ‰ç”¨æˆ·åé¦ˆæ—¶ï¼Œæ„å‘³ç€ä¹‹å‰çš„æ•´ä¸ªæµç¨‹å¯èƒ½éƒ½éœ€è¦é‡æ–°è®¡ç®—ã€‚
        # æœ€ç¨³å¦¥çš„åŠæ³•æ˜¯æ¸…ç©ºæ‰€æœ‰å·¥å…·ç¼“å­˜ã€‚
        original_text = context.get("text")
        if original_text:
            # æ¸…é™¤é¡¶å±‚ä»»åŠ¡ç¼“å­˜
            if original_text in mcp_server.context.run_cache:
                del mcp_server.context.run_cache[original_text]
                await ctx.info(f"â„¹ï¸ ç”¨æˆ·åé¦ˆå·²ä½¿é¡¶å±‚ä»»åŠ¡ '{original_text}' çš„ç¼“å­˜å¤±æ•ˆ")
            
            # æ¸…é™¤æ‰€æœ‰ç²¾ç»†åŒ–å·¥å…·ç¼“å­˜
            keys_to_del = [k for k in mcp_server.context.run_cache.keys() if "::" in k]
            if keys_to_del:
                for k in keys_to_del:
                    del mcp_server.context.run_cache[k]
                await ctx.info(f"â„¹ï¸ ç”¨æˆ·åé¦ˆå¯¼è‡´ {len(keys_to_del)} ä¸ªå·¥å…·ç¼“å­˜è¢«æ¸…é™¤")
        else:
             await ctx.warning("âš ï¸ æ— æ³•ç¡®å®šåé¦ˆå¯¹åº”çš„åŸå§‹ä»»åŠ¡ï¼Œç¼“å­˜å¯èƒ½æœªå®Œå…¨å¤±æ•ˆ")

        try:
            # ä¿®æ­£ï¼šç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½é€šè¿‡å…³é”®å­—ä¼ é€’ï¼Œé¿å…ä½ç½®å‚æ•°å†²çª
            result = await ctx.call_tool(
                "parse_user_feedback_tool",
                feedback_text=feedback_text,
                context=context
            )
            
            # æ›´æ–° MCP ä¸Šä¸‹æ–‡ä¸­çš„æ ¸å¿ƒå‚æ•°
            if "params" in result.get("mcp_context", {}):
                mcp_server.context.params.update(result["mcp_context"]["params"])

            # å°†è§£æå‡ºçš„å‚æ•°ä¹Ÿæ›´æ–°åˆ°å½“å‰ä»»åŠ¡çš„æœ¬åœ°ä¸Šä¸‹æ–‡ä¸­
            # ç¡®ä¿ context ä¸­æœ‰ params å­—å…¸
            if "params" not in context:
                context["params"] = {}
            context["params"].update(result["mcp_context"]["params"])
            await ctx.info("âœ… ç”¨æˆ·åé¦ˆå·²æ›´æ–°åˆ° MCPContext")
        except Exception as e:
            context.setdefault("errors", []).append(str(e))
            mcp_server.context.add_error(str(e))
            await ctx.error(f"åé¦ˆè§£æå¤±è´¥: {e}")
        return context



# ------------------------
# Data Agent
# ------------------------
class DataAgent(Agent):
    async def run(self, ctx: ExtendedContext, context: dict) -> dict:
        task = context.get("task")
        if not task:
            await ctx.error("ç¼ºå°‘ taskï¼ŒDataAgent æ— æ³•æ‰§è¡Œ")
            return context

        # ---- å…¼å®¹å•/å¤šå› ç´  ----
        variables = task.get("variables")
        if not variables:
            # å…¼å®¹æ—§çš„å•å› ç´ æ¨¡å¼
            variable = task.get("variable")
            if not variable:
                await ctx.error("ä»»åŠ¡ä¸­ç¼ºå°‘ 'variables' æˆ– 'variable' å­—æ®µ")
                return context
            variables = [variable]
        
        await ctx.info(f"ğŸ” DataAgent å¼€å§‹ä¸º {len(variables)} ä¸ªå˜é‡è·å–æ•°æ®: {variables}")

        data_points_by_variable = {}
        stratum = task.get("stratum")
        system = task.get("system")

        for variable in variables:
            await ctx.info(f"--- æ­£åœ¨æŸ¥è¯¢å˜é‡: {variable} ---")
            
            # ---- æ„é€ æŸ¥è¯¢æ–‡æœ¬ ----
            if system and not stratum:
                query_text = f"æŸ¥è¯¢ {system} å„äº• {variable} æ•°æ®ï¼ˆåŒ…å«å…¨éƒ¨å­åœ°å±‚ï¼‰"
            else:
                query_text = f"æŸ¥è¯¢ {stratum} å„äº• {variable} æ•°æ®"
            
            await ctx.info(f"ğŸ§­ æ•°æ®æ£€ç´¢ä»»åŠ¡: {query_text}")

            # ---- æ‰§è¡Œ SQL æŸ¥è¯¢ ----
            try:
                query_result = await ctx.call_tool("text_to_sql_query_tool", query=query_text)
                if not query_result or not query_result.get("rows"):
                    await ctx.warning(f"âš ï¸ å˜é‡ '{variable}' æœªè·å–åˆ°æœ‰æ•ˆäº•ç‚¹æ•°æ®")
                    continue
                
                await ctx.info(f"âœ… å˜é‡ '{variable}' è·å–åˆ° {len(query_result['rows'])} ä¸ªäº•ç‚¹æ•°æ®")
                data_points_by_variable[variable] = query_result["rows"]

            except Exception as e:
                context.setdefault("errors", []).append(f"å˜é‡ '{variable}' æŸ¥è¯¢å¤±è´¥: {str(e)}")
                await ctx.error(f"âŒ å˜é‡ '{variable}' æ•°æ®æŸ¥è¯¢å¤±è´¥: {e}")
                continue
        
        if not data_points_by_variable:
            await ctx.error("âŒ æ‰€æœ‰å˜é‡å‡æœªèƒ½è·å–åˆ°æ•°æ®ï¼Œæ— æ³•ç»§ç»­")
            return context

        # ---- å°†ç»“æœå†™å…¥ä¸Šä¸‹æ–‡ ----
        context["data_points_by_variable"] = data_points_by_variable
        mcp_server.context.data["data_points_by_variable"] = data_points_by_variable
        
        # ---- å…¼å®¹æ—§æ¨¡å¼ï¼šå¦‚æœåªæœ‰ä¸€ä¸ªå˜é‡ï¼Œåˆ™å¡«å……æ—§çš„ data_points å­—æ®µ ----
        if len(variables) == 1:
            single_variable = variables[0]
            if single_variable in data_points_by_variable:
                context["data_points"] = {"rows": data_points_by_variable[single_variable]}
                mcp_server.context.data["data_points"] = data_points_by_variable[single_variable]

        await ctx.info("âœ… æ‰€æœ‰å˜é‡æ•°æ®å·²è·å–å¹¶å†™å…¥ MCPContext")
        return context


# ------------------------
# Kriging Agent
# ------------------------
class KrigingAgent(Agent):
    async def run(self, ctx: ExtendedContext, context: dict) -> dict:
        # ---- å…¼å®¹æ–°æ—§æ•°æ®ç»“æ„ ----
        data_points_by_variable = context.get("data_points_by_variable")
        if not data_points_by_variable:
            # å…¼å®¹æ—§æ¨¡å¼
            rows = context.get("data_points", {}).get("rows", [])
            if not rows:
                await ctx.info("âš ï¸ æ— æ•°æ®ç‚¹ï¼Œè·³è¿‡ KrigingAgent")
                return context
            # å°†æ—§ç»“æ„åŒ…è£…æˆæ–°ç»“æ„
            variable = context.get("task", {}).get("variable", "unknown_variable")
            data_points_by_variable = {variable: rows}
            await ctx.info("ğŸ”„ æ£€æµ‹åˆ°æ—§ç‰ˆå•å› ç´ æ•°æ®ç»“æ„ï¼Œå·²è‡ªåŠ¨å…¼å®¹")

        task = context.get("task", {})
        kriging_results = {}

        await ctx.info(f"ğŸš€ KrigingAgent å¼€å§‹ä¸º {len(data_points_by_variable)} ä¸ªå˜é‡æ‰§è¡Œæ’å€¼...")

        for variable, rows in data_points_by_variable.items():
            await ctx.info(f"--- æ­£åœ¨æ’å€¼å˜é‡: {variable} ---")
            
            # --- å¢åŠ å¯¹å²©ç›¸å¤åœ°ç†è¿™ç±»åˆ†ç±»æ•°æ®çš„ç‰¹æ®Šå¤„ç† ---
            if variable == "å²©ç›¸å¤åœ°ç†":
                await ctx.info(f"â„¹ï¸ æ£€æµ‹åˆ°åˆ†ç±»æ•°æ® '{variable}'ï¼Œå°†è·³è¿‡æ•°å€¼æ’å€¼ï¼Œç›´æ¥è¿›è¡Œç‚¹æ¸²æŸ“ã€‚")
                kriging_results[variable] = {
                    "grid_x": None, "grid_y": None, "z": None,
                    "is_categorical_points": True,
                    "points": rows
                }
                # è¿™é‡Œæ˜¯å…³é”®ä¿®å¤ï¼šæˆ‘ä»¬åº”è¯¥ç›´æ¥ continueï¼Œå®Œå…¨è·³è¿‡åç»­çš„å·¥å…·è°ƒç”¨
                continue

            if len(rows) < 5:
                await ctx.error(f"âŒ å˜é‡ '{variable}' æ•°æ®ç‚¹è¿‡å°‘ ({len(rows)} ä¸ª)ï¼Œæ— æ³•æ‰§è¡Œæ’å€¼")
                kriging_results[variable] = {"error": "æ•°æ®ç‚¹ä¸è¶³"}
                continue

            # ---- æ•°æ®ç‚¹æ ¼å¼åŒ– ----
            points = []
            for p in rows:
                lon = p.get("lon") or p.get("geo_X")
                lat = p.get("lat") or p.get("geo_Y")
                value = p.get("value") or p.get("thickness") or p.get("ratio") or p.get("content")
                if None in (lon, lat, value):
                    continue
                points.append({"lon": float(lon), "lat": float(lat), "value": float(value)})

            # åªæœ‰åœ¨ points åˆ—è¡¨ä¸ä¸ºç©ºæ—¶æ‰æ‰§è¡Œæ’å€¼
            if not points:
                await ctx.warning(f"âš ï¸ å˜é‡ '{variable}' æ²¡æœ‰æœ‰æ•ˆçš„æ•°å€¼ç‚¹å¯ä¾›æ’å€¼ï¼Œå·²è·³è¿‡ã€‚")
                kriging_results[variable] = {"error": "æ— æœ‰æ•ˆæ•°å€¼ç‚¹"}
                continue

            try:
                # ---- å‚æ•°æå– ----
                params = mcp_server.context.params
                method_raw = params.get("method") or task.get("method_code") or "auto"
                model_raw = params.get("variogram_model") or task.get("model_code") or "auto"
                method_map = {"æ™®é€šå…‹é‡Œé‡‘": "ok", "æ³›å…‹é‡Œé‡‘": "uk", "universal_kriging": "uk", "ordinary_kriging": "ok", "åè·ç¦»åŠ æƒ": "idw", "idw": "idw"}
                method = method_map.get(str(method_raw).lower(), str(method_raw).lower())
                candidate_models = params.get("candidate_models", ["spherical", "exponential", "gaussian"])
                auto_optimize = params.get("auto_optimize", True)
                drift = params.get("drift", "linear")
                idw_power = params.get("idw_power", 2.0)

                if model_raw and model_raw != "auto":
                    candidate_models = [model_raw]
                    auto_optimize = False
                    await ctx.info(f"ğŸ¯ ç”¨æˆ·ä¸ºå˜é‡ '{variable}' æŒ‡å®šåŠå˜å¼‚å‡½æ•°æ¨¡å‹: {model_raw}")

                await ctx.info(f"âš™ï¸ å˜é‡ '{variable}' æ’å€¼å‚æ•°: method={method}, models={candidate_models}, drift={drift}")

                # ---- æ‰§è¡Œæ’å€¼ ----
                interp_result = await ctx.call_tool(
                    "kriging_interpolate",
                    points=points,
                    method=method,
                    candidate_models=candidate_models,
                    autoOptimizeModel=auto_optimize,
                    drift=drift,
                    idw_power=idw_power,
                )

                if not interp_result or "error" in interp_result:
                    raise Exception(interp_result.get("error", "æ’å€¼è¿”å›ç©ºç»“æœ"))

                kriging_results[variable] = interp_result
                await ctx.info(f"âœ… å˜é‡ '{variable}' æ’å€¼å®Œæˆ")

            except Exception as e:
                await ctx.error(f"âŒ å˜é‡ '{variable}' æ’å€¼å¤±è´¥: {e}")
                kriging_results[variable] = {"error": str(e)}

        # ---- å°†ç»“æœå†™å…¥ä¸Šä¸‹æ–‡ ----
        context["kriging_result"] = kriging_results
        mcp_server.context.results["kriging"] = kriging_results
        
        await ctx.info("âœ… æ‰€æœ‰å˜é‡æ’å€¼å®Œæˆï¼Œç»“æœå·²å†™å…¥ MCPContext")
        return context


# ------------------------
# Overlay Agent
# ------------------------
class OverlayAgent(Agent):
    # å®šä¹‰æ²‰ç§¯ç›¸åˆ†ç±»è§„åˆ™
    # è§„åˆ™æ ¼å¼: (æ²‰ç§¯ç›¸åç§°, é¢œè‰², lambdaå‡½æ•°)
    # lambda å‡½æ•°æ¥æ”¶ä¸€ä¸ªåŒ…å«æ‰€æœ‰å˜é‡å€¼çš„å­—å…¸ï¼Œè¿”å› True æˆ– False
    SEDIMENTARY_FACIES_RULES = [

        # ==========================================================
        # 1. ç«å±±ç¯å¢ƒï¼ˆç„æ­¦å²©ä¸ºä¸»ï¼Œå±äºé«˜èƒ½ç¯å¢ƒï¼‰
        # ==========================================================
        ("ç«å±±ç¯å¢ƒ", "#8B0000", lambda v: (
                v.get("ç„æ­¦å²©", 0) >= 0.50 and  # ç„æ­¦å²©å«é‡å¤§
                v.get("ç…¤å²©", 0) < 0.05 and  # ç…¤å²©å‡ ä¹æ²¡æœ‰
                v.get("ç¢³é…¸ç›å²©", 0) < 0.10  # ç¢³é…¸ç›å²©å°‘
        )),

        # ==========================================================
        # 2. ç¢³é…¸ç›å²©ç¯å¢ƒï¼ˆæµ…æµ·æˆ–æµ…æ¹–ç¯å¢ƒï¼‰
        # ==========================================================
        ("ç¢³é…¸ç›å²©ç¯å¢ƒ", "#32CD32", lambda v: (
                v.get("ç¢³é…¸ç›å²©", 0) >= 0.50 and  # ç¢³é…¸ç›å²©å«é‡å¤§
                v.get("ç¢å±‘å²©", 0) < 0.20 and  # ç¢å±‘å²©å°‘
                v.get("ç…¤å²©", 0) < 0.05  # ç…¤å²©å‡ ä¹æ²¡æœ‰
        )),

        # ==========================================================
        # 3. ä¸‰è§’æ´²ç¯å¢ƒï¼ˆç¢å±‘å²©å’Œç…¤å²©å«é‡è¾ƒé«˜ï¼‰
        # ==========================================================
        ("ä¸‰è§’æ´²ç¯å¢ƒ", "#FFD700", lambda v: (
                v.get("ç¢å±‘å²©", 0) >= 0.50 and  # ç¢å±‘å²©å ä¸»å¯¼
                v.get("ç…¤å²©", 0) <= 0.30 and  # ç…¤å²©æ¬¡è¦
                v.get("ç¢³é…¸ç›å²©", 0) < 0.10  # ç¢³é…¸ç›å²©å°‘
        )),

        # ==========================================================
        # 4. æ³»æ¹–ç¯å¢ƒï¼ˆè†ç›å²©ä¸ºä¸»ï¼Œå°‘é‡ç…¤å²©ï¼‰
        # ==========================================================
        ("æ³»æ¹–ç¯å¢ƒ", "#00FFFF", lambda v: (
                v.get("è†ç›å²©", 0) >= 0.50 and  # è†ç›å²©å ä¸»å¯¼
                v.get("ç…¤å²©", 0) <= 0.10 and  # ç…¤å²©å°‘
                v.get("ç¢å±‘å²©", 0) < 0.20  # ç¢å±‘å²©å°‘
        )),

        # ==========================================================
        # 5. æ²¼æ³½ç¯å¢ƒï¼ˆç…¤å²©ä¸ºä¸»ï¼‰
        # ==========================================================
        ("æ²¼æ³½ç¯å¢ƒ", "#2F4F4F", lambda v: (
                v.get("ç…¤å²©", 0) >= 0.50 and  # ç…¤å²©å ä¸»å¯¼
                v.get("ç¢å±‘å²©", 0) < 0.20 and  # ç¢å±‘å²©å°‘
                v.get("è†ç›å²©", 0) < 0.10  # è†ç›å²©å°‘
        )),

        # ==========================================================
        # 6. ç¡…è´¨æ²‰ç§¯ç¯å¢ƒï¼ˆç¡…å²©ä¸ºä¸»ï¼‰
        # ==========================================================
        ("ç¡…è´¨æ²‰ç§¯ç¯å¢ƒ", "#4682B4", lambda v: (
                v.get("ç¡…å²©", 0) >= 0.50 and  # ç¡…å²©å ä¸»å¯¼
                v.get("ç…¤å²©", 0) < 0.10 and  # ç…¤å²©å°‘
                v.get("ç¢å±‘å²©", 0) < 0.20  # ç¢å±‘å²©å°‘
        )),

        # ==========================================================
        # 7. æœªåˆ†ç±»ï¼ˆæ²¡æœ‰æ˜ç¡®å²©æ€§ç‰¹å¾æ—¶ä½¿ç”¨ï¼‰
        # ==========================================================
        ("æœªåˆ†ç±»", "#D3D3D3", lambda v: True)  # é»˜è®¤æœªåˆ†ç±»
    ]

    DEFAULT_FACIES = ("æœªåˆ†ç±»", "#D3D3D3")

    async def run(self, ctx: ExtendedContext, context: dict) -> dict:
        kriging_results = context.get("kriging_result", {})
        valid_factors = [f for f, r in kriging_results.items() if "error" not in r and "z" in r]

        if len(valid_factors) < 2:
            await ctx.info("âš ï¸ æœ‰æ•ˆæ’å€¼ç»“æœä¸è¶³ä¸¤ä¸ªï¼Œè·³è¿‡æ²‰ç§¯ç›¸åˆ†æ")
            if len(valid_factors) == 1:
                context["task"]["variable"] = valid_factors[0]
            return context

        await ctx.info(f"ğŸš€ å¼€å§‹åŸºäºè§„åˆ™çš„æ²‰ç§¯ç›¸åˆ†æï¼Œæ¶‰åŠå˜é‡: {valid_factors}")

        # ---- 1. å˜é‡åæ ‡å‡†åŒ– ----
        # åˆ›å»ºä¸€ä¸ªä»åŸå§‹å˜é‡ååˆ°æ ‡å‡†åŒ–åç§°ï¼ˆå¦‚â€œæ³¥å²©â€ï¼‰çš„æ˜ å°„
        key_mapping = {}
        for factor in valid_factors:
            # ç§»é™¤å¸¸è§çš„åç¼€
            clean_factor = factor.replace("åšåº¦", "").replace("å«é‡", "")
            key_mapping[factor] = clean_factor
        await ctx.info(f"â„¹ï¸ æ ‡å‡†åŒ–åå˜é‡åæ˜ å°„: {key_mapping}")

        # ---- 2. æå–æ‰€æœ‰æ’å€¼ç½‘æ ¼æ•°æ® (å¹¶ç¡®ä¿æ˜¯ numpy array) ----
        grids = {factor: np.array(kriging_results[factor]["z"]) for factor in valid_factors}
        
        # æ£€æŸ¥ç½‘æ ¼å½¢çŠ¶æ˜¯å¦ä¸€è‡´
        first_shape = next(iter(grids.values())).shape
        if not all(grid.shape == first_shape for grid in grids.values()):
            await ctx.error("âŒ å„å˜é‡æ’å€¼ç½‘æ ¼å½¢çŠ¶ä¸ä¸€è‡´ï¼Œæ— æ³•è¿›è¡Œåˆ†ç±»")
            return context
        
        grid_shape = first_shape

        # ---- 3. æ•°æ®å½’ä¸€åŒ–ï¼šå°†åšåº¦è½¬æ¢ä¸ºç™¾åˆ†æ¯” ----
        await ctx.info("âš–ï¸ å¼€å§‹è¿›è¡Œæ•°æ®å½’ä¸€åŒ–ï¼ˆåšåº¦ -> ç™¾åˆ†æ¯”ï¼‰")
        total_thickness = np.zeros(grid_shape)
        for factor in valid_factors:
            # å°†è´Ÿå€¼æˆ– NaN å€¼è§†ä¸º 0ï¼Œé¿å…å½±å“æ€»åšåº¦è®¡ç®—
            total_thickness += np.nan_to_num(grids[factor], nan=0.0, neginf=0.0, posinf=0.0)

        # é¿å…é™¤ä»¥é›¶
        total_thickness[total_thickness == 0] = 1.0

        normalized_grids = {factor: grids[factor] / total_thickness for factor in valid_factors}
        await ctx.info("âœ… æ•°æ®å½’ä¸€åŒ–å®Œæˆ")

        facies_grid = np.full(grid_shape, -1, dtype=int) # -1 ä»£è¡¨æœªåˆ†ç±»

        # ---- 4. å¢åŠ è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°ç¬¬ä¸€ä¸ªæœ‰æ•ˆç‚¹çš„æ•°æ® ----
        logged = False
        for r_idx in range(grid_shape[0]):
            for c_idx in range(grid_shape[1]):
                if not logged and total_thickness[r_idx, c_idx] > 1.0: # æ‰¾ä¸€ä¸ªæœ‰å®é™…åšåº¦çš„ç‚¹
                    raw_values = {f: grids[f][r_idx, c_idx] for f in valid_factors}
                    norm_values = {key_mapping[f]: normalized_grids[f][r_idx, c_idx] for f in valid_factors}
                    await ctx.info("---- ğŸ” è°ƒè¯•æ—¥å¿—ï¼šç¬¬ä¸€ä¸ªæœ‰æ•ˆç‚¹æ•°æ® ----")
                    await ctx.info(f"åæ ‡: ({r_idx}, {c_idx})")
                    await ctx.info(f"åŸå§‹åšåº¦å€¼: {raw_values}")
                    await ctx.info(f"è®¡ç®—å‡ºçš„æ€»åšåº¦: {total_thickness[r_idx, c_idx]}")
                    await ctx.info(f"å½’ä¸€åŒ–åçš„ç™¾åˆ†æ¯”: {norm_values}")
                    await ctx.info("------------------------------------")
                    logged = True
                    break
            if logged:
                break

        # ---- 5. é€ç‚¹åº”ç”¨è§„åˆ™è¿›è¡Œåˆ†ç±» ----
        for i in range(grid_shape[0]):
            for j in range(grid_shape[1]):
                # ä½¿ç”¨æ ‡å‡†åŒ–åçš„å˜é‡åæ„å»ºç”¨äºè§„åˆ™åˆ¤æ–­çš„å­—å…¸
                values_at_point = {key_mapping[factor]: normalized_grids[factor][i, j] for factor in valid_factors}
                
                # è·³è¿‡æ— æ•ˆç‚¹
                if any(np.isnan(v) for v in values_at_point.values()):
                    continue

                # åº”ç”¨è§„åˆ™
                classified = False
                for idx, (name, color, rule_func) in enumerate(self.SEDIMENTARY_FACIES_RULES):
                    if rule_func(values_at_point):
                        facies_grid[i, j] = idx
                        classified = True
                        break # åº”ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„è§„åˆ™
                
                if not classified:
                    facies_grid[i, j] = len(self.SEDIMENTARY_FACIES_RULES) # é»˜è®¤åˆ†ç±»çš„ç´¢å¼•

        # ---- 6. å‡†å¤‡åˆ†ç±»ç»“æœç”¨äºæ¸²æŸ“ ----
        # è·å– grid_x, grid_y
        grid_x = kriging_results[valid_factors[0]]["grid_x"]
        grid_y = kriging_results[valid_factors[0]]["grid_y"]

        # åˆ›å»ºé¢œè‰²æ˜ å°„å’Œæ ‡ç­¾
        facies_names = [name for name, _, _ in self.SEDIMENTARY_FACIES_RULES] + [self.DEFAULT_FACIES[0]]
        facies_colors = [color for _, color, _ in self.SEDIMENTARY_FACIES_RULES] + [self.DEFAULT_FACIES[1]]
        
        # å°†åˆ†ç±»ç»“æœæ‰“åŒ…ï¼Œä»¥å…¼å®¹åç»­çš„ MapRenderAgent
        # æ³¨æ„ï¼šæˆ‘ä»¬å°†åˆ†ç±»ç½‘æ ¼ï¼ˆæ•´æ•°ï¼‰æ”¾å…¥ 'z'ï¼Œå¹¶æä¾›åˆ†ç±»ä¿¡æ¯
        overlay_result = {
            "grid_x": grid_x,
            "grid_y": grid_y,
            "z": facies_grid,
            "is_categorical": True, # æ ‡è®°ä¸ºåˆ†ç±»æ•°æ®
            "categories": {
                "names": facies_names,
                "colors": facies_colors
            }
        }

        # ---- 7. å°†ç»“æœå†™å…¥ä¸Šä¸‹æ–‡ ----
        context["overlay_result"] = overlay_result
        mcp_server.context.results["overlay"] = overlay_result
        
        # æ›¿æ¢ kriging_result ä¸­çš„ç¬¬ä¸€ä¸ªç»“æœä¸ºæˆ‘ä»¬çš„åˆ†ç±»ç»“æœ
        # è¿™ä½¿å¾—åç»­çš„ MapRenderAgent å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªåˆ†ç±»ç»“æœè¿›è¡Œæ¸²æŸ“
        first_key = valid_factors[0]
        context["kriging_result"][first_key] = overlay_result
        context["task"]["variable"] = "æ²‰ç§¯ç›¸åˆ†å¸ƒ" # æ›´æ–°ä»»åŠ¡å˜é‡åï¼Œä»¥ä¾¿å›¾ä¾‹æ˜¾ç¤ºæ­£ç¡®

        await ctx.info("âœ… æ²‰ç§¯ç›¸åˆ†ç±»å®Œæˆï¼Œç»“æœå·²ç”Ÿæˆå¹¶ä¼ é€’ç»™æ¸²æŸ“æ¨¡å—")
        return context


# ------------------------
# MapRender Agent
# ------------------------
class MapRenderAgent(Agent):
    async def run(self, ctx: ExtendedContext, context: dict) -> dict:

        # await ctx.info(f"ğŸ¯ ç»˜å›¾å‰ MCPContext params: {mcp_server.context.params}")

        kriging_results = context.get("kriging_result") or mcp_server.context.results
        if not kriging_results:
            await ctx.info("âš ï¸ æ— æ’å€¼ç»“æœï¼Œè·³è¿‡ MapRenderAgent")
            return context

        # åœ¨å¤šå› ç´ åˆ†æåï¼Œkriging_results çš„ç¬¬ä¸€ä¸ªå…ƒç´ å·²è¢«æ›¿æ¢ä¸º overlay_result
        first_result = next(iter(kriging_results.values()))
        
        # --- å¯¹å²©ç›¸å¤åœ°ç†è¿™ç±»ç‰¹æ®Šåˆ†ç±»æ•°æ®è¿›è¡Œå¤„ç† ---
        if first_result.get("is_categorical_points"):
            await ctx.info("â„¹ï¸ æ¸²æŸ“åˆ†ç±»ç‚¹æ•°æ®...")
            # å¯¹äºåˆ†ç±»ç‚¹æ•°æ®ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨æ¸²æŸ“å·¥å…·ï¼Œä½†ä¸ä¼ é€’ç½‘æ ¼æ•°æ®
            res = await ctx.call_tool(
                "render_map_tool",
                grid_x=None,
                grid_y=None,
                z=None,
                first_result=first_result,
                points=first_result.get("points", []),
                variable=context.get("task", {}).get("variable"),
            )
            context["render_results"] = {
                "image_base64": res.get("image_base64"),
                "geojson": res.get("geojson"),
                "colors": res.get("colors", [])
            }
            await ctx.info("âœ… åˆ†ç±»ç‚¹æ•°æ®æ¸²æŸ“å®Œæˆ")
            return context

        try:
            # --- åˆå¹¶æ‰€æœ‰å˜é‡çš„æ•°æ®ç‚¹ç”¨äºæ¸²æŸ“ ---
            all_points = []
            if context.get("data_points_by_variable"):
                for points_list in context["data_points_by_variable"].values():
                    all_points.extend(points_list)
            else:
                # å…¼å®¹å•å› ç´ æ¨¡å¼
                all_points = context.get("data_points", {}).get("rows", [])

            params = mcp_server.context.params
            res = await ctx.call_tool(
                "render_map_tool",
                grid_x=first_result["grid_x"],
                grid_y=first_result["grid_y"],
                z=first_result["z"],
                first_result=first_result,  # ä¼ é€’å®Œæ•´ç»“æœä»¥åŒºåˆ†æ˜¯åˆ†ç±»æ•°æ®è¿˜æ˜¯è¿ç»­æ•°æ®
                points=all_points,
                variable=context.get("task", {}).get("variable"),
                colormap=params.get("colormap", "RdYlBu"),
                n_classes=params.get("n_classes"),
                smooth_sigma=params.get("smooth_sigma", 0),
                lighten=params.get("lighten", False)
            )
            # ---- å°†ç»“æœå’Œå‚æ•°å†™å…¥æœ¬åœ°å’Œå…¨å±€ä¸Šä¸‹æ–‡ ----
            render_results = {
                "image_base64": res.get("image_base64"),
                "geojson": res.get("geojson"),
                "colors": res.get("colors", [])
            }
            
            context["render_results"] = render_results
            mcp_server.context.results["render"] = render_results

            # ---- å›å†™æœ€ç»ˆä½¿ç”¨çš„æ¸²æŸ“å‚æ•°åˆ°å…¨å±€ä¸Šä¸‹æ–‡ ----
            final_render_params = {
                "colormap": params.get("colormap", "RdYlBu"),
                "n_classes": params.get("n_classes"),
                "smooth_sigma": params.get("smooth_sigma", 0),
                "lighten": params.get("lighten", False)
            }
            mcp_server.context.params.update(final_render_params)

            await ctx.info("âœ… æ¸²æŸ“ç»“æœå’Œæœ€ç»ˆä½¿ç”¨å‚æ•°å·²å†™å…¥ MCPContext")
        except Exception as e:
            await ctx.error(f"âŒ åœ°å›¾æ¸²æŸ“å¤±è´¥: {e}")
            context.setdefault("errors", []).append(str(e))
            mcp_server.context.add_error(str(e))

        return context
