import numpy as np
import asyncio
from typing import Dict, Any, List, Optional
from mcp_server import mcp_server
from data_query import text_to_sql_query
from nlp_processor import parse_text_tool
from kriging import Interpolator
from image import MapRenderer
from feedback_processor import parse_user_feedback
from functools import wraps
import inspect

def mcp_tool_history(history_key: str, extract_input=None):
    """
    è£…é¥°å™¨ï¼šè‡ªåŠ¨ç®¡ç† MCP å·¥å…·å†å²ä¸Šä¸‹æ–‡
    - history_key: ctx.memory ä¸­çš„å†å²è®°å½• key
    - extract_input: å‡½æ•°ï¼Œæå–è¾“å…¥æ•°æ®å­˜å…¥å†å²
    è‡ªåŠ¨è®°å½• mcp_server.context.params å½“å‰çŠ¶æ€
    """
    def decorator(func):
        if asyncio.iscoroutinefunction(func):
            @wraps(func)
            async def async_wrapper(ctx, *args, **kwargs):
                if not hasattr(ctx, "memory"):
                    ctx.memory = {}
                ctx.memory.setdefault(history_key, [])

                # æå–å·¥å…·è¾“å…¥
                input_data = extract_input(*((ctx,) + args), **kwargs) if extract_input else {"args": args, "kwargs": kwargs}

                # è®°å½•å½“å‰ MCPContext.params
                input_data["context_params"] = getattr(mcp_server.context, "params", {}).copy()

                # æ™ºèƒ½è°ƒç”¨ï¼šæ£€æŸ¥ func æ˜¯å¦æ¥å— 'ctx'
                sig = inspect.signature(func)
                if 'ctx' in sig.parameters:
                    result = await func(ctx, *args, **kwargs)
                else:
                    result = await func(*args, **kwargs)

                # ä¿å­˜å†å²
                ctx.memory[history_key].append({"input": input_data, "result": result})
                return result

            return async_wrapper
        else:
            @wraps(func)
            def sync_wrapper(ctx, *args, **kwargs):
                if not hasattr(ctx, "memory"):
                    ctx.memory = {}
                ctx.memory.setdefault(history_key, [])

                input_data = extract_input(*((ctx,) + args), **kwargs) if extract_input else {"args": args, "kwargs": kwargs}
                input_data["context_params"] = getattr(mcp_server.context, "params", {}).copy()

                # ä¿®æ­£ï¼šä¸åº”å°† ctx ä¼ é€’ç»™åŸå§‹å‡½æ•°
                result = func(*args, **kwargs)
                ctx.memory[history_key].append({"input": input_data, "result": result})
                return result

            return sync_wrapper

    return decorator

# ----------------- MCP å†å²è®°å½•æå–å‡½æ•° -----------------
def extract_kriging_input(ctx, points, **kwargs):
    """
    MCP å†å²è®°å½•æå–å‡½æ•°ï¼Œå…¼å®¹æ‰€æœ‰å…³é”®å­—å‚æ•°
    """
    return {
        "points_count": len(points),
        "method": kwargs.get("method", "ok"),
        "candidate_models": kwargs.get("candidate_models", ["spherical", "exponential", "gaussian"]),
        "autoOptimizeModel": kwargs.get("autoOptimizeModel", False),
        "drift": kwargs.get("drift", "linear")
    }

# ---------------------------
# NLP è§£æå·¥å…·
# ---------------------------
@mcp_server.tool()
@mcp_tool_history("nlp_history", extract_input=lambda ctx, user_text, context=None: {"user_text": user_text})
def parse_text_tool_mcp(user_text: str, context: dict | None = None) -> Dict[str, Any]:
    """
    NLP è§£æå·¥å…·ï¼Œæ”¯æŒé»‘æ¿å¼ä¸Šä¸‹æ–‡
    """
    result = parse_text_tool(user_text)
    if "task" in result and "warnings" not in result["task"]:
        result["task"]["warnings"] = []
    if "plan" in result and "errors" not in result["plan"]:
        result["plan"]["errors"] = []
    if context is not None:
        # ç›´æ¥å†™å…¥é»‘æ¿ä¸Šä¸‹æ–‡
        context["parsed_result"] = result
        context["task"] = result.get("task", {})
        context["plan"] = result.get("plan", {"pipeline": []})
    return result

# ---------------------------
# Text2SQL å·¥å…·
# ---------------------------

@mcp_tool_history("query_history", extract_input=lambda ctx, query: {"query": query})
@mcp_server.tool()
def text_to_sql_query_tool(ctx, query: str):
    return text_to_sql_query(query)


# ---------------------------
# Kriging æ’å€¼å·¥å…·
# ---------------------------
interpolator = Interpolator()

@mcp_server.tool()
@mcp_tool_history(
    "kriging_history",
    extract_input=lambda ctx, points, **kwargs: {
        "points_count": len(points),
        "method": kwargs.get("method", "auto"),
        "candidate_models": kwargs.get("candidate_models", ["spherical", "exponential", "gaussian"]),
        "autoOptimizeModel": kwargs.get("autoOptimizeModel", True),
        "drift": kwargs.get("drift", "linear"),
        "idw_power": kwargs.get("idw_power", 2.0)
    }
)
async def kriging_interpolate(
    ctx,
    points: list[dict],
    method: str = "auto",
    candidate_models=None,
    autoOptimizeModel=True,
    drift="linear",
    idw_power: float = 2.0,
    **kwargs
):
    # === ğŸ§© è°ƒè¯•è¯­å¥ï¼šè¾“å‡º points çš„ç¤ºä¾‹ç»“æ„ ===
    print("\n[DEBUG] ====== Kriging è¾“å…¥ç‚¹ä¿¡æ¯ ======")
    try:
        # å°è¯•å–å‰ 3 ä¸ªæ ·æœ¬
        sample = points[:3] if isinstance(points, (list, tuple)) else list(points)[:3]
        print(f"[DEBUG] è¾“å…¥ç‚¹æ€»æ•°: {len(points)}")
        for i, p in enumerate(sample):
            print(f"[DEBUG] ç¤ºä¾‹ç‚¹ {i}: ç±»å‹={type(p)} | å†…å®¹={repr(p)}")
            try:
                print(f"[DEBUG]    é•¿åº¦={len(p)}")
                if hasattr(p, "keys"):
                    print(f"[DEBUG]    é”®é›†åˆ={list(p.keys())}")
            except Exception as e:
                print(f"[DEBUG]    é•¿åº¦æ£€æµ‹å¼‚å¸¸: {e}")
    except Exception as e:
        print(f"[DEBUG] âŒ æ— æ³•æ‰“å°è¾“å…¥ç‚¹ç¤ºä¾‹: {e}")
    print("[DEBUG] ==================================\n")

    if not points:
        return {"error": "ç¼ºå°‘ points æ•°æ®"}

        # ------------------- âœ… æ ¼å¼ç»Ÿä¸€ä¸é¢„å¤„ç† -------------------
    parsed_points = []
    for p in points:
        if isinstance(p, dict):
            lon = p.get("lon") or p.get("x") or p.get("lng") or p.get("geo_X")
            lat = p.get("lat") or p.get("y") or p.get("geo_Y")
            val = p.get("value") or p.get("z") or p.get("v") or p.get("thickness")
            if lon is not None and lat is not None and val is not None:
                parsed_points.append({"lon": float(lon), "lat": float(lat), "value": float(val)})
        elif isinstance(p, (list, tuple)):
            if len(p) >= 3:
                parsed_points.append({"lon": float(p[0]), "lat": float(p[1]), "value": float(p[2])})
    if not parsed_points:
        return {"error": "åæ ‡/æ•°å€¼æå–å¤±è´¥: è¾“å…¥ç‚¹ç»“æ„ä¸ç¬¦åˆè¦æ±‚"}

    points = parsed_points

    candidate_models = candidate_models or ["spherical", "exponential", "gaussian"]

    # ------------------- æå–åæ ‡ä¸å€¼ -------------------
    try:
        lons = np.array([p.get("lon") or p.get("geo_X") for p in points], dtype=float)
        lats = np.array([p.get("lat") or p.get("geo_Y") for p in points], dtype=float)
        values = np.array([p.get("value") or p.get("thickness") for p in points], dtype=float)
        print(f"[INFO] æ•°æ®ç‚¹æ•°é‡: {len(values)}")
    except Exception as e:
        return {"error": f"åæ ‡/æ•°å€¼æå–å¤±è´¥: {e}"}

    # ------------------- æ•°æ®æœ‰æ•ˆæ€§ -------------------
    mask = np.isfinite(values)
    lons, lats, values = lons[mask], lats[mask], values[mask]
    if len(values) < 5:
        return {"error": "æœ‰æ•ˆæ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œæ’å€¼"}

    # ------------------- è‡ªåŠ¨åˆ¤æ–­æ’å€¼æ–¹æ³• -------------------
    if method == "auto":
        suggestion = interpolator.suggest_kriging_method(lons, lats, values)
        method = suggestion["suggestion"]
        print(f"[INFO] è‡ªåŠ¨é€‰æ‹©æ’å€¼æ–¹æ³•: {method.upper()} ({suggestion['reason']})")
    else:
        print(f"[INFO] ç”¨æˆ·æŒ‡å®šæ’å€¼æ–¹æ³•: {method.upper()}")

    # ------------------- æ­£æ€æ€§æ£€æµ‹ + Box-Cox -------------------

    values_transformed, lmbda, was_transformed, shift, shapiro_p = interpolator.check_normality_and_transform(values)
    mean, std = values_transformed.mean(), values_transformed.std()
    values_std = (values_transformed - mean) / (std if std > 0 else 1.0)
    boxcox_info = {"was_transformed": was_transformed, "lambda": lmbda, "shift": shift, "shapiro_p": shapiro_p}

    # ------------------- è‡ªåŠ¨ä¼˜åŒ–åŠå˜å¼‚æ¨¡å‹ (ä»… Kriging) -------------------
    final_model = None
    model_scores = {}
    if method != "idw":
        print(f"[INFO] æ­£åœ¨é€‰æ‹©æœ€ä¼˜åŠå˜å¼‚å‡½æ•°æ¨¡å‹...")
        best_model, all_models = interpolator.select_best_model(lons, lats, values_std, candidate_models=candidate_models)
        if best_model is None:
            return {"error": "åŠå˜å¼‚å‡½æ•°æ¨¡å‹é€‰æ‹©å¤±è´¥", "details": all_models}
        print(f"[INFO] æœ€ä¼˜åŠå˜å¼‚å‡½æ•°æ¨¡å‹: {best_model}")

        # ------------------- å¹¶è¡Œäº¤å‰éªŒè¯ -------------------
        async def cv_task(model_name):
            print(f"[INFO] æ­£åœ¨è¿›è¡Œäº¤å‰éªŒè¯...")
            params = {"method": method, "variogram_model": model_name, "autoOptimizeModel": autoOptimizeModel, "drift": drift}
            try:
                n_points = len(values_std)
                sample_size = min(n_points, 30)
                idx = np.random.choice(n_points, sample_size, replace=False)
                cv_res = await asyncio.to_thread(interpolator.cross_validate, lons[idx], lats[idx], values[idx], params)
                return model_name, cv_res
            except Exception as e:
                return model_name, {"error": str(e)}

        tasks = [cv_task(m) for m in candidate_models]
        cv_results_list = await asyncio.gather(*tasks)

        model_scores = {}
        best_score = float("inf")
        best_cv_model = best_model
        for model_name, cv_res in cv_results_list:
            model_scores[model_name] = cv_res
            if "KRMSE" in cv_res and cv_res["KRMSE"] < best_score:
                best_cv_model = model_name
                best_score = cv_res["KRMSE"]
        final_model = best_cv_model or best_model
        print(f"[INFO] æœ€ç»ˆé‡‡ç”¨æ¨¡å‹: {final_model}")
    else:
        # IDW ä¸éœ€è¦æ¨¡å‹ï¼Œæ‰€ä»¥è·³è¿‡ä»¥ä¸Šæ­¥éª¤
        final_model = None
        model_scores = {}

    final_params = {"method": method, "variogram_model": final_model, "autoOptimizeModel": autoOptimizeModel, "drift": drift, "idw_power": idw_power}

    # ------------------- å®‰å…¨æ’å€¼ -------------------
    def safe_interpolate(lons, lats, values, params, **kwargs):
        try:
            res = interpolator.interpolate(lons, lats, values, params, **kwargs)
            print("[DEBUG] æ’å€¼å‡½æ•°è¿”å›ç±»å‹:", type(res))
            if isinstance(res, (tuple, list)):
                print("[DEBUG] è¿”å›å…ƒç´ æ•°é‡:", len(res))
                for i, item in enumerate(res):
                    print(f"   [DEBUG] ç¬¬ {i} é¡¹ç±»å‹: {type(item)}")
            elif isinstance(res, dict):
                print("[DEBUG] è¿”å›ä¸ºå­—å…¸ï¼Œé”®é›†åˆ:", list(res.keys()))
        except Exception as e:
            return {"error": f"æ’å€¼æ‰§è¡Œå¤±è´¥: {e}", "z": None, "ss": None, "grid_x": None, "grid_y": None}

        z = ss = grid_x = grid_y = None

        if isinstance(res, (tuple, list)):
            n = len(res)
            if n >= 1: z = res[0]
            if n >= 2: ss = res[1]
            if n >= 3: grid_x = res[2]
            if n >= 4: grid_y = res[3]
        elif isinstance(res, dict):
            z = res.get("z") or res.get("zk")
            ss = res.get("ss") or res.get("variance")
            grid_x = res.get("grid_x") or res.get("grid_lon")
            grid_y = res.get("grid_y") or res.get("grid_lat")
        else:
            return {"error": f"æœªçŸ¥è¿”å›ç±»å‹: {type(res)}", "z": None, "ss": None, "grid_x": None, "grid_y": None}

        # è‡ªåŠ¨ç”Ÿæˆç½‘æ ¼
        if grid_x is None or grid_y is None:
            try:
                nx = ny = 100
                if np.ptp(lons) == 0: lons[0] += 1e-6
                if np.ptp(lats) == 0: lats[0] += 1e-6
                grid_x, grid_y = np.meshgrid(np.linspace(np.min(lons), np.max(lons), nx),
                                             np.linspace(np.min(lats), np.max(lats), ny))
            except Exception:
                grid_x = grid_y = None

        return {"z": z, "ss": ss, "grid_x": grid_x, "grid_y": grid_y}

    final_interp = await asyncio.to_thread(safe_interpolate, lons, lats, values, final_params, **kwargs)

    # ------------------- æ±‡æ€»è¾“å‡º -------------------
    final_interp.update({
        "boxcox_info": boxcox_info,
        "selected_method": method,
        "best_model": final_model,
        "cv_results": model_scores,
        "points_count": len(values)
    })

    return final_interp


# ---------------------------
# Kriging å åŠ åˆ†æå·¥å…·
# ---------------------------
@mcp_server.tool()
@mcp_tool_history(
    "overlay_history",
    extract_input=lambda ctx, datasets, weights, **kwargs: {
        "dataset_names": list(datasets.keys()),
        "weights": weights,
        "common_params": kwargs
    }
)
async def kriging_overlay_tool(
    ctx,
    datasets: Dict[str, Dict[str, List[float]]],
    weights: Dict[str, float],
    **kwargs
) -> Dict[str, Any]:
    """
    å¯¹å¤šä¸ªæ•°æ®é›†è¿›è¡Œæ’å€¼å¹¶è¿›è¡ŒåŠ æƒå åŠ ã€‚
    `datasets`: {'æ³¥å²©': {'lons': [...], 'lats': [...], 'values': [...]}, ...}
    `weights`: {'æ³¥å²©': 0.6, 'ç°å²©': 0.4}
    `kwargs`: å…±äº«çš„æ’å€¼å‚æ•°
    """
    if not datasets or not weights:
        return {"error": "Datasets and weights are required."}

    try:
        # æ³¨æ„ï¼šInterpolator() æ˜¯åŒæ­¥ä»£ç ï¼Œä½†åœ¨å¼‚æ­¥å‡½æ•°ä¸­è°ƒç”¨å…¶åŒæ­¥æ–¹æ³•æ˜¯å®‰å…¨çš„
        # å¦‚æœ interpolate_and_overlay æ˜¯CPUå¯†é›†å‹æ“ä½œï¼Œæœªæ¥å¯ä»¥è€ƒè™‘ç”¨ asyncio.to_thread
        result = interpolator.interpolate_and_overlay(
            datasets=datasets,
            weights=weights,
            common_params=kwargs
        )
        return result
    except Exception as e:
        return {"error": f"Overlay analysis failed: {str(e)}"}


# ---------------------------
# åœ°å›¾æ¸²æŸ“å·¥å…·
# ---------------------------
renderer = MapRenderer()


@mcp_server.tool()
@mcp_tool_history(
    "map_render_history",
    extract_input=lambda ctx, grid_x, grid_y, z, points=None, **kwargs: {
        "grid_size": (len(grid_x), len(grid_y)),
        "points_count": len(points) if points else 0,
        "variable": kwargs.get("variable", "thickness"),
        "colormap": kwargs.get("colormap", "RdYlBu"),
        "n_classes": kwargs.get("n_classes", None)
    }
)
async def render_map_tool(ctx, grid_x, grid_y, z, first_result=None,
                          points=None, boundary_geom=None,
                          task_text=None, variable="thickness", lithology=None,
                          smooth_sigma=0, n_classes=11, colormap="RdYlBu",
                          lighten=False):
    result = await renderer.render_map(
        grid_x, grid_y, z, first_result,
        points, boundary_geom,
        task_text, variable, lithology,
        smooth_sigma, n_classes,
        colormap, lighten
    )

    return result


# ---------------------------
# ç”¨æˆ·åé¦ˆè§£æå·¥å…·
# ---------------------------
@mcp_server.tool()
@mcp_tool_history("feedback_history", extract_input=lambda ctx, feedback_text, context=None: {"feedback_text": feedback_text})
async def parse_user_feedback_tool(feedback_text: str, context: Optional[dict] = None) -> dict:
    result = await parse_user_feedback(feedback_text, context)
    if context is not None:
        for k, v in result.get("mcp_context", {}).get("params", {}).items():
            context[k] = v
    return result
